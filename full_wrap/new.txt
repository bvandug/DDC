# simulink_env.py   (R2024b-compatible, Rapid Accelerator + state-saving)
import gym
from gym import spaces
import numpy as np
import matlab.engine
import os, shutil, tempfile, uuid


class SimulinkEnv(gym.Env):
    """Fast Simulink RL environment (Rapid Accelerator, Fast-Restart OFF)."""

    metadata = {"render.modes": []}

    # ---------------------------------------
    # constructor
    # ---------------------------------------
    def __init__(
        self,
        model_name: str = "PendCart",
        agent_block: str = "PendCart/DRL",
        dt: float = 0.01,
        max_episode_time: float = 5.0,
        angle_threshold: float = np.pi / 3,
    ):
        super().__init__()
        print("Starting MATLAB engine ...")
        self.eng = matlab.engine.start_matlab()

        # unique copy so multiple envs/processes don't clash
        uid = uuid.uuid4().hex[:8]
        self.model_name = f"{model_name}_{uid}"
        self.model_path = os.path.join(tempfile.gettempdir(), f"{self.model_name}.slx")
        shutil.copy(f"{model_name}.slx", self.model_path)

        # load the model
        self.eng.load_system(self.model_path, nargout=0)

        # Run in Rapid Accelerator (Fast-Restart stays OFF)
        self.eng.set_param(self.model_name, "SimulationMode", "rapid", nargout=0)

        # fixed-step solver
        self.dt = dt
        self.eng.set_param(
            self.model_name,
            "SolverType",
            "Fixed-step",
            "Solver",
            "ode4",
            "FixedStep",
            str(dt),
            nargout=0,
        )

        # RL bookkeeping
        self.agent_block = agent_block
        self.max_episode_time = max_episode_time
        self.angle_threshold = angle_threshold
        self.current_time = 0.0

        # Spaces
        max_force = 10.0
        self.action_space = spaces.Box(
            low=-max_force, high=max_force, shape=(1,), dtype=np.float32
        )
        hi = np.array([np.pi, np.finfo(np.float32).max], np.float32)
        self.observation_space = spaces.Box(-hi, hi, dtype=np.float32)

        # Compile RA target + create initial SimState
        self._prime_kernel()

    # ---------------------------------------
    # helpers
    # ---------------------------------------
    def _prime_kernel(self):
        """Build Rapid-Accelerator target and capture initial SimState."""
        # 1) build once (takes a few seconds)
        self.eng.feval(
            "Simulink.BlockDiagram.buildRapidAcceleratorTarget",
            self.model_name,
            nargout=0,
        )

        # 2) tiny run to grab xFinal
        simOut = self.eng.feval(
            "sim",
            self.model_name,
            "SimulationMode",
            "rapid",
            "RapidAcceleratorUpToDateCheck",
            "off",
            "StopTime",
            "1e-4",
            "SaveFinalState",
            "on",
            "SaveFormat",
            "StructureWithTime",  # RA-safe format
            "FinalStateName",
            "xFinal",
            nargout=1,
        )
        # expose to base workspace so eval() works
        self.eng.workspace["out"] = simOut
        self.eng.eval("xFinal = out.xFinal;", nargout=0)

    # ---------------------------------------
    # Gym API
    # ---------------------------------------
    def reset(self, *, seed=None, options=None):
        super().reset(seed=seed)
        self.current_time = 0.0

        # random non-zero starting angle
        theta0 = float(self.np_random.uniform(-1.0, 1.0))
        while -0.05 < theta0 < 0.05:
            theta0 = float(self.np_random.uniform(-1.0, 1.0))
        self.eng.set_param(
            f"{self.model_name}/Pendulum and Cart", "init", str(theta0), nargout=0
        )

        # re-seed noise blocks
        for blk in ["Noise", "Noise_v"]:
            seed_val = int(self.np_random.integers(1, 50000))
            self.eng.set_param(
                f"{self.model_name}/{blk}",
                "seed",
                f"[{seed_val}]",
                "Cov",
                "[0]",
                nargout=0,
            )

        # tiny run to refresh SimState
        simOut = self.eng.feval(
            "sim",
            self.model_name,
            "SimulationMode",
            "rapid",
            "RapidAcceleratorUpToDateCheck",
            "off",
            "StopTime",
            "1e-4",
            "SaveFinalState",
            "on",
            "SaveFormat",
            "StructureWithTime",
            "FinalStateName",
            "xFinal",
            nargout=1,
        )
        self.eng.workspace["out"] = simOut
        self.eng.eval("xFinal = out.xFinal;", nargout=0)

        theta, vel = self._latest_state()
        # ────────────────────────────────
        # RETURN OBSERVATION ONLY HERE
        # ────────────────────────────────
        return np.array([theta, vel], dtype=np.float32)

    def step(self, action):
        # 1) push action
        u = float(np.clip(action, self.action_space.low, self.action_space.high))
        self.eng.set_param(f"{self.model_name}/Constant", "Value", str(u), nargout=0)

        # 2) micro-run
        stop_t = self.current_time + self.dt
        simOut = self.eng.feval(
            "sim",
            self.model_name,
            "SimulationMode",
            "rapid",
            "RapidAcceleratorUpToDateCheck",
            "off",
            "LoadInitialState",
            "on",
            "InitialState",
            "xFinal",
            "StopTime",
            f"{stop_t}",
            "SaveFinalState",
            "on",
            "SaveFormat",
            "StructureWithTime",
            "FinalStateName",
            "xFinal",
            nargout=1,
        )
        self.eng.workspace["out"] = simOut
        self.eng.eval("xFinal = out.xFinal;", nargout=0)
        self.current_time = stop_t

        # 3) obs / reward / done
        theta, vel = self._latest_state()
        obs = np.array([theta, vel], dtype=np.float32)
        reward = np.cos(theta) - 0.5 * vel**2 - 0.05 * u**2
        done = abs(theta) > self.angle_threshold or stop_t >= self.max_episode_time
        return obs, reward, done, {"time": stop_t}

    # ---------------------------------------
    # utilities
    # ---------------------------------------
    def _latest_state(self):
        theta = float(self.eng.eval("out.angle(end)", nargout=1))
        vel = 0.0
        if self.current_time > 0:
            prev_theta = float(self.eng.eval("out.angle(end-1)", nargout=1))
            vel = (theta - prev_theta) / self.dt
        return theta, vel

    def render(self, mode="human"):
        pass

    def close(self):
        self.eng.quit()
        try:
            os.remove(self.model_path)
        except OSError:
            pass
